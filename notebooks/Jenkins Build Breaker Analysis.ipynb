{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need the <tt>log</tt> files of the first level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "ROOT_DIR = r\"C:/Temp/build_logs\"\n",
    "GLOB_PATTERN = \"*/*/log\"\n",
    "log_file_paths = glob.glob(ROOT_DIR + \"/\" + GLOB_PATTERN)\n",
    "log_file_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean up these ugly, different, OS specific file separators by using the common one. (Note: We could have also used <tt>os.sep</tt>, but if you extract e. g. by a regex, it's getting unreadable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_file_paths = [path.replace(\"\\\\\", \"/\") for path in log_file_paths]\n",
    "log_file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "logs = pd.DataFrame(log_file_paths, columns=['path'])\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the path, we can extract the name of t he Jenkins job as well as the build number of the executed job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = logs.join(logs['path'].str.extract(r\"^.*/(?P<jobname>.*)/(?P<buildnumber>.*)/log$\", expand=True))\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dateien aus Ordner in Liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def load_content(file_path):\n",
    "    lines = []\n",
    "    with open(file_path, mode='r', encoding=\"utf-8\") as f:\n",
    "        #lines = reversed(deque(f, 200))\n",
    "        lines = deque(f, 200)\n",
    "        \n",
    "    return \"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_content_via_csv(file_path):\n",
    "    series = pd.read_csv(file_path, sep=\"\\u0012\", header=None, encoding=\"utf-8\")[0]\n",
    "    return \"\\n\".join(series[-200:].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could take some time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs['content'] = logs['path'].apply(load_content)\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs['finished'] = logs['content'].str.extract(r\"Finished: (.*)\\n\", expand=False)\n",
    "print(str(len(logs[~logs['finished'].isnull()])) + \"/\" + str(len(logs)) + ' identified by \"Finished:\" marker.')\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auflistung der nicht zuordbaren Builds (kann z. B. durch das Abbrechen des Kopiervorgangs durch das gleichzeitige schreiben der Datei verursacht worden sein)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs.ix[logs['finished'].isnull(), 'finished'] = \"UNKNOWN\"\n",
    "assert len(logs[logs['finished'].isnull()]) == 0, \"Non treated pattern for failures.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifcation of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(logs['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark successful executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successfull_executions = logs['finished'] == \"SUCCESS\"\n",
    "number_of_successfull_executions = len(logs[successfull_executions])\n",
    "logs.ix[successfull_executions, 'error'] = \"none\"\n",
    "print(str(number_of_successfull_executions) + \"/\" + str(len(logs)) + ' builds identified as successfull.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General\n",
    "First, try to extract the message behind the first <tt>ERROR</tt> marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_successful = logs['error'].isnull()\n",
    "non_successful_logs = logs[non_successful]\n",
    "error_state = non_successful_logs['content'].str.extract(r\"\\n\\[?ERROR\\]?.*? (.*)\\n\", expand=False)\n",
    "logs.ix[non_successful, 'error'] = error_state\n",
    "print(str(len(non_successful_logs)) + \"/\" + str(len(logs)) + ' builds identified by \"ERROR\" markers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SonarQube errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SONAR_ERROR_MARKER = \"SonarQube analysis completed: FAILURE\"\n",
    "sonar_errors = (logs['error'].isnull()) & (logs['content'].str.contains(SONAR_ERROR_MARKER))\n",
    "number_of_sonar_errors = len(logs[sonar_errors])\n",
    "logs.ix[sonar_errors, 'error'] = SONAR_ERROR_MARKER\n",
    "print(str(number_of_sonar_errors) + \"/\" + str(len(logs)) + ' errors identified by \"SonarQube\" markers.')\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed execution of Maven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overrides already existing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAVEN_BUILD_FAILURE = \"\\[INFO\\] BUILD FAILURE\"\n",
    "FAILED_GOAL_MARKER = \"\\[ERROR\\] Failed to execute goal\"\n",
    "fail_maven_execution = (logs['content'].str.contains(MAVEN_BUILD_FAILURE)) & (logs['content'].str.contains(FAILED_GOAL_MARKER))\n",
    "print(\"Overriding existing, wrongly marked entries: \" + str(len(logs[fail_maven_goals & (~logs['error'].isnull())])))\n",
    "fail_maven_goals_logs = logs[fail_maven_execution]\n",
    "fail_goals = fail_maven_goals_logs['content'].str.extract(\".*(\" + FAILED_GOAL_MARKER + \" .*?) \", expand=False)\n",
    "logs.ix[fail_maven_execution, 'finished'] = \"BUILD_FAILURE\"\n",
    "logs.ix[fail_maven_execution, 'error'] = fail_goals\n",
    "print(str(len(fail_maven_goals_logs)) + \"/\" + str(len(logs)) + ' builds identified as fails goals.')\n",
    "fail_maven_goals_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs.ix[logs['error'].isnull(), 'error'] = \"UNTREATED\"\n",
    "print(\"Untreated cases: \" + str(len(logs[logs['error'] == \"UNTREATED\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_breaker = logs.groupby(['finished', 'error']).count()[['path']]\n",
    "build_breaker = build_breaker.rename(columns = { 'path' : 'count'})\n",
    "build_breaker.to_excel(\"build_breaker.xlsx\")\n",
    "build_breaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the reasons behind the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional statistics about test executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing <tt>Test Data: run, failures, errors, skipped</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = logs.join(logs['content'].str.extract(r\"\\nTests run: (?P<test_run>[0-9]*), Failures: (?P<test_failures>[0-9]*), Errors: (?P<test_errors>[0-9]*), Skipped: (?P<test_skipped>[0-9])\\n\", expand=True))\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs['totaltime'] = logs['content'].str.extract(r\"\\n\\[INFO\\] Total time: ([0-9]*\\.[0-9]*).*\\n\", expand=False)\n",
    "logs['totaltime'] = logs['totaltime'].apply(pd.to_numeric)\n",
    "logs['finish'] = logs['content'].str.extract(r\"\\n\\[INFO\\] Finished at: (.*)\\n\", expand=False)\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logs[logs['finished'] == \"SUCCESS\"].groupby('jobname').max()['totaltime'].dropna().plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
